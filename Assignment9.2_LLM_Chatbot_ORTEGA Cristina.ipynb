{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab3ea23-43df-40d2-bdc7-b75f0393bc51",
   "metadata": {},
   "source": [
    "Assignment 9.2: Chatbot using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c95a2a-6f38-4b7e-919e-00615e100f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (1.45.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: torch in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (2.7.1+cpu)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (1.24.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (4.14.1)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cristina ortega\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7030ae7-c6b4-4d82-9ed8-0adab38f3700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae2435cb0504e9eaf7aac11de0ebef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristina Ortega\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Cristina Ortega\\.cache\\huggingface\\hub\\models--distilgpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bd07c46836425c991821787043dcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4998504a9940349b40aaccd137a844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78314d040ac4be49603ff31446b02fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76d3d8c6b3e4b549be92a967550a639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a3d2435e31427b8ab1ff160b6c2ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f13825712e74a59ae4cd4121aab579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "2025-07-08 15:01:24.224 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.058 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Cristina Ortega\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-08 15:01:31.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.062 Session state does not function when running a script without `streamlit run`\n",
      "2025-07-08 15:01:31.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-08 15:01:31.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "\n",
    "st.title(\"Chatbot with LLM\")\n",
    "\n",
    "if 'history' not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "\n",
    "def generate_response(prompt):\n",
    "    output = generator(prompt, max_new_tokens=50, do_sample=True, temperature=0.7)[0]['generated_text']\n",
    "    return output[len(prompt):].strip()\n",
    "\n",
    "user_input = st.text_input(\"Tú:\", key=\"input\")\n",
    "\n",
    "if user_input:\n",
    "    st.session_state.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    conversation = \"\"\n",
    "    for chat in st.session_state.history:\n",
    "        conversation += f\"{chat['role']}: {chat['content']}\\n\"\n",
    "\n",
    "    response = generate_response(conversation + \"assistant: \")\n",
    "\n",
    "    st.session_state.history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "for chat in st.session_state.history:\n",
    "    if chat['role'] == 'user':\n",
    "        st.markdown(f\"**Tú:** {chat['content']}\")\n",
    "    else:\n",
    "        st.markdown(f\"**Bot:** {chat['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d10eac0-af03-42fa-8b21-fa7511a8061a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Cristina Ortega\\\\NLP'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58863c99-4316-48e6-acbf-640d41797697",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\"\"\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "\n",
    "st.title(\"Clasificador de Emails con LLM\")\n",
    "\n",
    "email = st.text_area(\"Introduce el contenido del email:\")\n",
    "\n",
    "if email:\n",
    "    generator = pipeline('text-generation', model='gpt2')\n",
    "    prompt = f\"Classify this email as 'spam' or 'not spam'. Only reply with 'spam' or 'not spam'. Email: {email}\\\\nLabel:\"\n",
    "    output = generator(prompt, max_new_tokens=10, do_sample=False)[0]['generated_text']\n",
    "    \n",
    "    # Extraer solo la etiqueta desde el prompt generado\n",
    "    result = output.split(\"Label:\")[-1].strip().split(\"\\\\n\")[0]\n",
    "    \n",
    "    st.subheader(\"Clasificación:\")\n",
    "    st.write(result)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c96d6a-da54-43b0-b0ae-f251e51d6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
